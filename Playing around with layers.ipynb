{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: 'net' is not in the list of known options, but still passed to Electron/Chromium.\n",
      "Warning: 'spec' is not in the list of known options, but still passed to Electron/Chromium.\n"
     ]
    }
   ],
   "source": [
    "!  code/verifier.py --net fc1 --spec ../test_cases/fc1/img0_0.06200.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Play around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = torch.randn(20)\n",
    "high = torch.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao\n"
     ]
    }
   ],
   "source": [
    "if (low[2]>0 or high[2]<0): print(\"Ciao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye\n"
     ]
    }
   ],
   "source": [
    "if sum((b[9]>b).int())==9: print(\"bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = high/(high-low+1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3757,  0.1847,  0.3286,  0.0281,  0.0796, -0.1315, -0.3567,  0.5412,\n",
       "         3.3045, -0.2847, -7.8086,  9.1827, -0.1897, -3.4624, -3.2016, -0.4401,\n",
       "        -0.6775, -0.1525,  1.5915,  0.4968])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(low*high)/(high-low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(low) == torch.matmul(linear.weight, low) + linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in a[-10:]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "b +=[low]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Wrong",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-aa92a33442cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: Wrong"
     ]
    }
   ],
   "source": [
    "raise Exception(\"Wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the weight is negative we need to use the high, not the low to obtain the bound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Linear' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-cb597765576f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'Linear' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "linear.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0558,  0.0158, -0.1341,  0.1626, -0.0597,  0.1036, -0.0944, -0.0719,\n",
      "        -0.2125,  0.1777, -0.2232, -0.1800,  0.0116, -0.1082, -0.0118, -0.1463,\n",
      "        -0.0617, -0.0626, -0.1268,  0.0666], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0147,  0.1199, -0.0593, -0.1118, -0.1764, -0.1687,  0.1288, -0.1503,\n",
      "         0.0783, -0.1326,  0.1362,  0.2211,  0.1578, -0.2030,  0.1177, -0.0703,\n",
      "         0.2056,  0.0665,  0.1757, -0.0239], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.1869,  0.1830,  0.1869, -0.1717,  0.0445,  0.0641, -0.1594, -0.1314,\n",
      "         0.2000,  0.0184,  0.0527,  0.0838,  0.0467, -0.1228,  0.1430, -0.0104,\n",
      "         0.2204,  0.1752, -0.1517,  0.1391], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0695, -0.1829,  0.0295,  0.0978,  0.0731, -0.1585, -0.0772, -0.0126,\n",
      "         0.1225, -0.0426, -0.1674, -0.0967,  0.0584, -0.1384, -0.0300,  0.1834,\n",
      "        -0.1476,  0.1262,  0.1966, -0.0284], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1247,  0.0291,  0.1527, -0.1003, -0.2017,  0.0979, -0.1391, -0.1740,\n",
      "         0.2112, -0.1550, -0.1281, -0.1582,  0.1640, -0.1642,  0.1343, -0.1349,\n",
      "        -0.0980, -0.1099, -0.1914,  0.0991], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0683,  0.1017,  0.1404, -0.1983, -0.2097, -0.0948,  0.0343,  0.1629,\n",
      "        -0.0334,  0.1319,  0.1117,  0.2230, -0.1178,  0.1158,  0.0879,  0.0814,\n",
      "        -0.2069,  0.2113,  0.1818,  0.0651], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0233, -0.1994,  0.0778, -0.0513,  0.1080, -0.0613,  0.1148, -0.0234,\n",
      "         0.0010,  0.1633, -0.1990, -0.0617,  0.0706,  0.1631, -0.0186, -0.1109,\n",
      "        -0.0951, -0.1925, -0.1377,  0.1522], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.0602,  0.1374,  0.0682, -0.1330, -0.1479, -0.0029,  0.2180,  0.0048,\n",
      "         0.1726,  0.0355, -0.0786, -0.1543,  0.1590,  0.0101,  0.0692,  0.1974,\n",
      "         0.1192,  0.0676, -0.0561,  0.1613], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.2201, -0.0273,  0.0341,  0.1659, -0.1530, -0.2229,  0.0481,  0.0437,\n",
      "        -0.2115,  0.0958,  0.2216, -0.0778,  0.2053, -0.0457, -0.0795, -0.1148,\n",
      "         0.1722, -0.0462,  0.2030, -0.2033], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1170, -0.2097,  0.0885, -0.1496,  0.1811,  0.0502, -0.1852,  0.2114,\n",
      "        -0.0227, -0.0462, -0.2143,  0.1533,  0.0666,  0.0908, -0.0161,  0.1792,\n",
      "         0.0789,  0.0978, -0.0087,  0.0576], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0006,  0.0324,  0.0182,  0.1273, -0.2235,  0.0940,  0.0504, -0.0154,\n",
      "         0.0780, -0.0973, -0.0083,  0.0867,  0.2228,  0.2221,  0.1283,  0.0534,\n",
      "        -0.0905, -0.1267,  0.0054,  0.0111], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.1986, -0.1980, -0.0696, -0.1424, -0.1856, -0.0341, -0.1409, -0.2181,\n",
      "        -0.0089, -0.0953, -0.1061,  0.1403, -0.0972, -0.1228,  0.2035,  0.0110,\n",
      "        -0.1200,  0.1270, -0.1642,  0.0398], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.0682,  0.2150, -0.1253,  0.1839, -0.0184, -0.0053,  0.1904, -0.1454,\n",
      "        -0.1570, -0.2032, -0.0362,  0.0944,  0.0043, -0.1212,  0.1457,  0.2127,\n",
      "         0.1738, -0.1119,  0.1756,  0.0420], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1409, -0.1762, -0.0578, -0.1769,  0.1167,  0.1253, -0.0608, -0.1990,\n",
      "        -0.0522, -0.0094,  0.1586, -0.1713,  0.1114, -0.0247,  0.1591, -0.1897,\n",
      "        -0.0859,  0.0462, -0.0065,  0.0849], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0079, -0.1106, -0.1839, -0.0559, -0.1427, -0.1680, -0.0462, -0.1155,\n",
      "         0.0921,  0.1032, -0.0033, -0.1480, -0.0646, -0.2012,  0.1720, -0.1174,\n",
      "         0.1991, -0.2192,  0.1483, -0.1843], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0603,  0.1520,  0.2098,  0.1188, -0.1637, -0.0901,  0.1790, -0.0290,\n",
      "        -0.1326,  0.0430,  0.0241,  0.1798, -0.1610, -0.0324, -0.1221,  0.0432,\n",
      "        -0.0538,  0.1926, -0.0042,  0.1380], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.2094, -0.0227, -0.1469,  0.1431, -0.0800, -0.1471,  0.0396, -0.0151,\n",
      "        -0.0661, -0.0780,  0.1469,  0.2215, -0.0472, -0.1443,  0.2144,  0.1056,\n",
      "        -0.1524,  0.1730,  0.1627,  0.1639], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.2116, -0.0797,  0.2212, -0.1888, -0.0562,  0.0092, -0.2005, -0.2118,\n",
      "         0.1082,  0.0202, -0.1745, -0.2001, -0.0879,  0.0022, -0.0019,  0.1344,\n",
      "        -0.1469, -0.1035, -0.0257, -0.0779], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1928,  0.1152, -0.0283, -0.2014, -0.1905, -0.0756,  0.0453,  0.0307,\n",
      "        -0.0003, -0.0713,  0.0123,  0.0976, -0.1439,  0.0182, -0.0462,  0.1959,\n",
      "         0.1850,  0.0663, -0.0368,  0.0471], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.0452, -0.0976,  0.1971,  0.0171, -0.0258, -0.1560,  0.0778,  0.0667,\n",
      "        -0.1488, -0.0722, -0.0986, -0.0097,  0.0071,  0.1889,  0.1319, -0.1304,\n",
      "        -0.0631,  0.0750,  0.0993, -0.0368], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.0864, -0.0711, -0.0448, -0.1960, -0.1974, -0.0503, -0.1560,  0.1680,\n",
      "         0.0019, -0.1694, -0.0498,  0.1996, -0.1513,  0.1215, -0.0379, -0.0525,\n",
      "        -0.0272, -0.1786, -0.1299,  0.1246], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1413, -0.1512,  0.0997,  0.0465, -0.1931,  0.2049,  0.0128, -0.1584,\n",
      "        -0.1542, -0.1666, -0.1120, -0.1339,  0.1815,  0.1958, -0.1765, -0.1451,\n",
      "         0.1859,  0.0375,  0.1260,  0.0575], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.0656,  0.0515, -0.1052, -0.0250,  0.1653,  0.0667,  0.2014,  0.2174,\n",
      "         0.0578, -0.1498,  0.0795,  0.1968, -0.1004,  0.1844, -0.1711,  0.2114,\n",
      "         0.1097,  0.1771,  0.0358, -0.1516], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1291, -0.0050, -0.1667, -0.1896, -0.1210, -0.1707, -0.1637,  0.2018,\n",
      "        -0.1615, -0.0929,  0.1726, -0.1034,  0.1936, -0.0770,  0.0511,  0.1692,\n",
      "         0.0693,  0.0078, -0.0327, -0.2147], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.0937,  0.0332,  0.0990, -0.0448,  0.1693,  0.2206,  0.0589,  0.1628,\n",
      "         0.1607,  0.1535, -0.1060,  0.1727, -0.1471, -0.1164, -0.1450, -0.0900,\n",
      "        -0.2109,  0.0122, -0.1384,  0.2144], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.1632,  0.0898,  0.0778,  0.1529,  0.0550,  0.1047, -0.0693,  0.2194,\n",
      "        -0.0605, -0.1980, -0.0012,  0.0829, -0.1290, -0.1504, -0.0277,  0.0335,\n",
      "         0.1987,  0.1049,  0.0924, -0.1604], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.2205, -0.1146,  0.2227, -0.1136,  0.1296,  0.1653,  0.2136,  0.2044,\n",
      "         0.1508,  0.1864,  0.2026,  0.2127,  0.2150, -0.0537,  0.1511,  0.1812,\n",
      "        -0.1727, -0.1543,  0.0613,  0.0833], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.1412, -0.0731, -0.1318, -0.2097, -0.2102, -0.1438,  0.1475, -0.1534,\n",
      "         0.1409, -0.2051,  0.1113,  0.1314,  0.2036, -0.0341, -0.2043, -0.0939,\n",
      "         0.1261,  0.1061, -0.0390, -0.0326], grad_fn=<UnbindBackward>)\n",
      "tensor([ 0.2034, -0.2216, -0.0742, -0.0991, -0.1260,  0.2167,  0.0092,  0.1146,\n",
      "        -0.0864,  0.1316, -0.0269, -0.0673, -0.1263,  0.0903, -0.1567, -0.0741,\n",
      "         0.0880, -0.0334,  0.0776, -0.1892], grad_fn=<UnbindBackward>)\n",
      "tensor([-0.1698,  0.2034, -0.0271, -0.1278, -0.0965,  0.1604,  0.0925,  0.0439,\n",
      "         0.0873, -0.0837, -0.0429,  0.0055, -0.1566,  0.0149, -0.1354, -0.0787,\n",
      "         0.0628, -0.1063, -0.1866,  0.2142], grad_fn=<UnbindBackward>)\n"
     ]
    }
   ],
   "source": [
    "for w in W: \n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_high = (w<0).int()\n",
    "mask_low = (w>=0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_low*low+ mask_high*low == low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(w.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4045, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(w, low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(linear) == torch.nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = 0, 0 , 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.eye(20,20)\n",
    "for i in range(20): b[i,i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 =  torch.eye(20,20)*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(W,b) == torch.matmul(W,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0558,  0.0158, -0.1341,  0.1626, -0.0597,  0.1036, -0.0944, -0.0719,\n",
       "         -0.2125,  0.1777, -0.2232, -0.1800,  0.0116, -0.1082, -0.0118, -0.1463,\n",
       "         -0.0617, -0.0626, -0.1268,  0.0666],\n",
       "        [ 0.0147,  0.1199, -0.0593, -0.1118, -0.1764, -0.1687,  0.1288, -0.1503,\n",
       "          0.0783, -0.1326,  0.1362,  0.2211,  0.1578, -0.2030,  0.1177, -0.0703,\n",
       "          0.2056,  0.0665,  0.1757, -0.0239],\n",
       "        [-0.1869,  0.1830,  0.1869, -0.1717,  0.0445,  0.0641, -0.1594, -0.1314,\n",
       "          0.2000,  0.0184,  0.0527,  0.0838,  0.0467, -0.1228,  0.1430, -0.0104,\n",
       "          0.2204,  0.1752, -0.1517,  0.1391],\n",
       "        [ 0.0695, -0.1829,  0.0295,  0.0978,  0.0731, -0.1585, -0.0772, -0.0126,\n",
       "          0.1225, -0.0426, -0.1674, -0.0967,  0.0584, -0.1384, -0.0300,  0.1834,\n",
       "         -0.1476,  0.1262,  0.1966, -0.0284],\n",
       "        [ 0.1247,  0.0291,  0.1527, -0.1003, -0.2017,  0.0979, -0.1391, -0.1740,\n",
       "          0.2112, -0.1550, -0.1281, -0.1582,  0.1640, -0.1642,  0.1343, -0.1349,\n",
       "         -0.0980, -0.1099, -0.1914,  0.0991],\n",
       "        [ 0.0683,  0.1017,  0.1404, -0.1983, -0.2097, -0.0948,  0.0343,  0.1629,\n",
       "         -0.0334,  0.1319,  0.1117,  0.2230, -0.1178,  0.1158,  0.0879,  0.0814,\n",
       "         -0.2069,  0.2113,  0.1818,  0.0651],\n",
       "        [ 0.0233, -0.1994,  0.0778, -0.0513,  0.1080, -0.0613,  0.1148, -0.0234,\n",
       "          0.0010,  0.1633, -0.1990, -0.0617,  0.0706,  0.1631, -0.0186, -0.1109,\n",
       "         -0.0951, -0.1925, -0.1377,  0.1522],\n",
       "        [-0.0602,  0.1374,  0.0682, -0.1330, -0.1479, -0.0029,  0.2180,  0.0048,\n",
       "          0.1726,  0.0355, -0.0786, -0.1543,  0.1590,  0.0101,  0.0692,  0.1974,\n",
       "          0.1192,  0.0676, -0.0561,  0.1613],\n",
       "        [-0.2201, -0.0273,  0.0341,  0.1659, -0.1530, -0.2229,  0.0481,  0.0437,\n",
       "         -0.2115,  0.0958,  0.2216, -0.0778,  0.2053, -0.0457, -0.0795, -0.1148,\n",
       "          0.1722, -0.0462,  0.2030, -0.2033],\n",
       "        [ 0.1170, -0.2097,  0.0885, -0.1496,  0.1811,  0.0502, -0.1852,  0.2114,\n",
       "         -0.0227, -0.0462, -0.2143,  0.1533,  0.0666,  0.0908, -0.0161,  0.1792,\n",
       "          0.0789,  0.0978, -0.0087,  0.0576],\n",
       "        [ 0.0006,  0.0324,  0.0182,  0.1273, -0.2235,  0.0940,  0.0504, -0.0154,\n",
       "          0.0780, -0.0973, -0.0083,  0.0867,  0.2228,  0.2221,  0.1283,  0.0534,\n",
       "         -0.0905, -0.1267,  0.0054,  0.0111],\n",
       "        [-0.1986, -0.1980, -0.0696, -0.1424, -0.1856, -0.0341, -0.1409, -0.2181,\n",
       "         -0.0089, -0.0953, -0.1061,  0.1403, -0.0972, -0.1228,  0.2035,  0.0110,\n",
       "         -0.1200,  0.1270, -0.1642,  0.0398],\n",
       "        [-0.0682,  0.2150, -0.1253,  0.1839, -0.0184, -0.0053,  0.1904, -0.1454,\n",
       "         -0.1570, -0.2032, -0.0362,  0.0944,  0.0043, -0.1212,  0.1457,  0.2127,\n",
       "          0.1738, -0.1119,  0.1756,  0.0420],\n",
       "        [ 0.1409, -0.1762, -0.0578, -0.1769,  0.1167,  0.1253, -0.0608, -0.1990,\n",
       "         -0.0522, -0.0094,  0.1586, -0.1713,  0.1114, -0.0247,  0.1591, -0.1897,\n",
       "         -0.0859,  0.0462, -0.0065,  0.0849],\n",
       "        [ 0.0079, -0.1106, -0.1839, -0.0559, -0.1427, -0.1680, -0.0462, -0.1155,\n",
       "          0.0921,  0.1032, -0.0033, -0.1480, -0.0646, -0.2012,  0.1720, -0.1174,\n",
       "          0.1991, -0.2192,  0.1483, -0.1843],\n",
       "        [ 0.0603,  0.1520,  0.2098,  0.1188, -0.1637, -0.0901,  0.1790, -0.0290,\n",
       "         -0.1326,  0.0430,  0.0241,  0.1798, -0.1610, -0.0324, -0.1221,  0.0432,\n",
       "         -0.0538,  0.1926, -0.0042,  0.1380],\n",
       "        [-0.2094, -0.0227, -0.1469,  0.1431, -0.0800, -0.1471,  0.0396, -0.0151,\n",
       "         -0.0661, -0.0780,  0.1469,  0.2215, -0.0472, -0.1443,  0.2144,  0.1056,\n",
       "         -0.1524,  0.1730,  0.1627,  0.1639],\n",
       "        [ 0.2116, -0.0797,  0.2212, -0.1888, -0.0562,  0.0092, -0.2005, -0.2118,\n",
       "          0.1082,  0.0202, -0.1745, -0.2001, -0.0879,  0.0022, -0.0019,  0.1344,\n",
       "         -0.1469, -0.1035, -0.0257, -0.0779],\n",
       "        [ 0.1928,  0.1152, -0.0283, -0.2014, -0.1905, -0.0756,  0.0453,  0.0307,\n",
       "         -0.0003, -0.0713,  0.0123,  0.0976, -0.1439,  0.0182, -0.0462,  0.1959,\n",
       "          0.1850,  0.0663, -0.0368,  0.0471],\n",
       "        [-0.0452, -0.0976,  0.1971,  0.0171, -0.0258, -0.1560,  0.0778,  0.0667,\n",
       "         -0.1488, -0.0722, -0.0986, -0.0097,  0.0071,  0.1889,  0.1319, -0.1304,\n",
       "         -0.0631,  0.0750,  0.0993, -0.0368],\n",
       "        [ 0.0864, -0.0711, -0.0448, -0.1960, -0.1974, -0.0503, -0.1560,  0.1680,\n",
       "          0.0019, -0.1694, -0.0498,  0.1996, -0.1513,  0.1215, -0.0379, -0.0525,\n",
       "         -0.0272, -0.1786, -0.1299,  0.1246],\n",
       "        [ 0.1413, -0.1512,  0.0997,  0.0465, -0.1931,  0.2049,  0.0128, -0.1584,\n",
       "         -0.1542, -0.1666, -0.1120, -0.1339,  0.1815,  0.1958, -0.1765, -0.1451,\n",
       "          0.1859,  0.0375,  0.1260,  0.0575],\n",
       "        [-0.0656,  0.0515, -0.1052, -0.0250,  0.1653,  0.0667,  0.2014,  0.2174,\n",
       "          0.0578, -0.1498,  0.0795,  0.1968, -0.1004,  0.1844, -0.1711,  0.2114,\n",
       "          0.1097,  0.1771,  0.0358, -0.1516],\n",
       "        [ 0.1291, -0.0050, -0.1667, -0.1896, -0.1210, -0.1707, -0.1637,  0.2018,\n",
       "         -0.1615, -0.0929,  0.1726, -0.1034,  0.1936, -0.0770,  0.0511,  0.1692,\n",
       "          0.0693,  0.0078, -0.0327, -0.2147],\n",
       "        [-0.0937,  0.0332,  0.0990, -0.0448,  0.1693,  0.2206,  0.0589,  0.1628,\n",
       "          0.1607,  0.1535, -0.1060,  0.1727, -0.1471, -0.1164, -0.1450, -0.0900,\n",
       "         -0.2109,  0.0122, -0.1384,  0.2144],\n",
       "        [-0.1632,  0.0898,  0.0778,  0.1529,  0.0550,  0.1047, -0.0693,  0.2194,\n",
       "         -0.0605, -0.1980, -0.0012,  0.0829, -0.1290, -0.1504, -0.0277,  0.0335,\n",
       "          0.1987,  0.1049,  0.0924, -0.1604],\n",
       "        [-0.2205, -0.1146,  0.2227, -0.1136,  0.1296,  0.1653,  0.2136,  0.2044,\n",
       "          0.1508,  0.1864,  0.2026,  0.2127,  0.2150, -0.0537,  0.1511,  0.1812,\n",
       "         -0.1727, -0.1543,  0.0613,  0.0833],\n",
       "        [ 0.1412, -0.0731, -0.1318, -0.2097, -0.2102, -0.1438,  0.1475, -0.1534,\n",
       "          0.1409, -0.2051,  0.1113,  0.1314,  0.2036, -0.0341, -0.2043, -0.0939,\n",
       "          0.1261,  0.1061, -0.0390, -0.0326],\n",
       "        [ 0.2034, -0.2216, -0.0742, -0.0991, -0.1260,  0.2167,  0.0092,  0.1146,\n",
       "         -0.0864,  0.1316, -0.0269, -0.0673, -0.1263,  0.0903, -0.1567, -0.0741,\n",
       "          0.0880, -0.0334,  0.0776, -0.1892],\n",
       "        [-0.1698,  0.2034, -0.0271, -0.1278, -0.0965,  0.1604,  0.0925,  0.0439,\n",
       "          0.0873, -0.0837, -0.0429,  0.0055, -0.1566,  0.0149, -0.1354, -0.0787,\n",
       "          0.0628, -0.1063, -0.1866,  0.2142]], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:,3]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.eye(10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.zeros(9) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.numpy().all()>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = nn.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(t).squeeze()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = torch.eye(9)*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "c = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([mm[:,0:n],torch.ones(c-1,1),mm[:,n:c]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm[:,1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitd07bf4d1d7ec47a9b9a7ee499ad6e1d2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
